{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine_Learning_01.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOAcsaC9idrmVFN1xFyk8JX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myounghunseo/Python/blob/master/Machine_Learning_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQMdUFSlvnIq"
      },
      "source": [
        "## What can you do with Machine_Learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta3Sd1nKwAfq"
      },
      "source": [
        "* 고객을 나누고 각 그룹에 맞는 최신의 마케팅 전략 찾기\r\n",
        "* 비슷한 고개의 구매 이력을 기반으로 상품 추천하기\r\n",
        "* 부정 거래 감지하기\r\n",
        "* 내년도 매출 예측하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz_N0XuNw0ZH"
      },
      "source": [
        "## Goals and Methods\r\n",
        "\r\n",
        "* Scikit_Learn : \r\n",
        "    - 사이킷런은 매우 사용하기 쉽고 많은 머싱러닝 알고리즘이 효율적으로 구현되어 있습니다. \r\n",
        "    - 머신러닝을 처음 배울 때 사용하기 아주 좋습니다.\r\n",
        "* TensorFlow : \r\n",
        "    - 텐서플로는 분산 수치 계산을 위해 data flow graph를 사용하는 탁월한 라이브러리 입니다. \r\n",
        "    - 수천 대의 다중 GPU 서버에 계산을 분산하여 대규모 신경망을 효과적으로 훈련하고 실행시킬 수 있습니다.\r\n",
        "    - 구글에서 만들었고, 구글의 대규모 머신러닝 애플리케이션에서 사용하고 있습니다.(2015년 11월에 오픈소스로 공개되었습니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBKNjiQHyEt2"
      },
      "source": [
        "## Necessary Skills\r\n",
        "* 파이썬의 주요 과학 라이브러리인 Numpy, Pandas, Matplotlib 들이 친숙해야합니다.\r\n",
        "* 이론적 배경을 이해하려면, 미적분, 선형대수, 확률, 통계 등의 대학 수준의 수학 지식도 필요합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMuc8lMAzOsP"
      },
      "source": [
        "## Data Mining\r\n",
        "* 머신러닝 기술을 적용해서 대용량의 데이터를 분석하면, 겉으로는 보이지 않던 패턴을 발견 할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJCMhimtXS1g"
      },
      "source": [
        "## Types of Meachine-Learning systems\r\n",
        "\r\n",
        "1. Surpervised and Unsurpervised learning\r\n",
        "2. Batch learning and Online learning\r\n",
        "3. Case-based and Model-based learning\r\n",
        "4. Key challenges in Machine Learning\r\n",
        "5. Testing and Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XzP5X2L0xnv"
      },
      "source": [
        "## Types of Meachine-Learning systems\r\n",
        "\r\n",
        "1. Surpervised and Unsurpervised learning\r\n",
        "    - 지도학습 : 분류 , 독립변수-label(정답), 예측 변수-특성(feature)\r\n",
        "        - k-최근접 이웃\r\n",
        "        - 선형 회귀\r\n",
        "        - 로지스틱 회귀\r\n",
        "        - 서포트 벡터 머신\r\n",
        "        - 결정 트리와 랜덤 포레스트\r\n",
        "        - 신경망\r\n",
        "    - 비지도 학습 : 훈련 데이터에 label(정답)이 없습니다.\r\n",
        "        - 군집\r\n",
        "        - 시각화와 차원 축소\r\n",
        "        - 연관 규칙 학습\r\n",
        "    - 준지도 학습 : 레이블이 없는 데이터가 많고, 레이블이 있는 데이터는 아주 조금입니다.\r\n",
        "    - 강화 학습 : 매우 다른 종류의 알고리즘 입니다.\r\n",
        "        - 에이전트 : 학습하는 시스템\r\n",
        "        - 환경(environment)을 관찰해서 행동(action)을 실행하고\r\n",
        "        - 그 결과로 보상(reward) 또는 벌점(penalty)를 받습니다.\r\n",
        "        - 시간이 지나면서 가장 큰 보상을 얻기 위해 정책(policy)이라고 부르는 최상의 전략을 스스로 학습니다.\r\n",
        "2. Batch learning and Online learning\r\n",
        "    - **배치 학습**에서는 시스템이 점진적으로 학습할 수 없습니다.\r\n",
        "    - 먼저 시스템을 훈련시키고 그런 다음 제품 시스템에 적용하면, 더 이상의 학습 없이 실행됩니다. 즉, 학습한 것을 적용만 합니다.\r\n",
        "    - 이를 **오프라인 학습(Offline learning)**이라고 합니다.\r\n",
        "    - **온라인 학습(Online learning)**에서는 데이터를 순차적으로 한 개씩 또는 **미니배치(mini-batch)**라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킵니다.\r\n",
        "    - 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습 할 수 있습니다.\r\n",
        "3. Case-based and Model-based learning\r\n",
        "    - 머신러닝 시스템은 어떻게 일반화되는가에 따라 분류할 수도 있습니다.\r\n",
        "    - 머신러닝의 작업은 예측을 만드는 것입니다.\r\n",
        "    - 이 말은 훈련 데이터로 학습하지만 훈련 데이터에서는 본적 없는 새로운 데이터로 일반화되어야 한다는 뜻.\r\n",
        "    - 훈련 데이터에서 높은 성능을 내는 것이 좋지만, 진짜 목표는 새로운 샘플에 잘 작동하는 모델입니다.\r\n",
        "    - 일반화를 위한 두가지 접근법 : **사례 기반 학습과 모델 기반 학습** 입니다.\r\n",
        "    - 사례 기반 학습 : 유사도 측정, 스팸 메일 분류 문제의 경우, 두 메일 사이의 간단한 유사도 측정 방식은 공통으로 포함된 단어의 수를 세는 것입니다.\r\n",
        "    - 시스템이 사례를 기억함으로써 학습하고, 유사도 측정을 사용해 데이터에 일반화하는 것.\r\n",
        "    - **모델 기반 학습** : 샘플로부터 일반화시키는 방법은 샘플들의 모델의 만들어 예측에 사용하는 것입니다.\r\n",
        "    - 모델링 - model selection - linear model 선택(예시)\r\n",
        "    - 모델 파라미터\r\n",
        "    - 모델의 성능평가는 어떻게 할 수 있을까요? \r\n",
        "    - 효용 함수(적합도 함수) 또는 비용 함수를 정의\r\n",
        "    - 선형 회귀에서는 보통 선형 모델의 예측과 훈련 데이터 사이의 거리를 재는 비용 함수를 사용합니다.\r\n",
        "    - 이 거리를 최소화하는 것을 목표로 합니다.\r\n",
        "    - 선형 회귀 알고리즘\r\n",
        "        - 알고리즘에 훈련 데이터를 공급하면, 데이터에 가장 잘 맞는 선형 모델의 파라미터를 찾아줍니다. 이를 훈련(training)이라고 합니다.\r\n",
        "\r\n",
        "    -  **Work Flow**\r\n",
        "        1. 데이터를 분석합니다.\r\n",
        "        2. 모델을 선택합니다.\r\n",
        "        3. 훈련 데이터로 모델을 훈련시킵니다.\r\n",
        "        (학습 알고리즘이 비용 함수를 최소화하는 모델 파라미터를 찾습니다)\r\n",
        "        4. 새로운 데이터에 모델을 적용해 예측하고(이를 **추론(inference)**이로고 합니다)\r\n",
        "        (이 모델이 잘 일반화되길 기대합니다)\r\n",
        "4. Key challenges in Machine Learning\r\n",
        "    1. 충분하지 않은 양의 훈련 데이터\r\n",
        "    2. 대표성 없는 훈련 데이터 : 일반화가 잘 되려면 우리가 일반화하기 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요합니다.\r\n",
        "        - 샘플이 작으면, **샘플링 잡음(sampling noise)**이 생기고\r\n",
        "        - 매우 큰 샘플도 표본 추출 방법이 잘못되면, 대표선을 띠지 못할 수 있습니다.\r\n",
        "        - 이를 **샘플링 편향(sampling bias)**이라고 합니다.\r\n",
        "    3. 낮은 품질의 데이터 \r\n",
        "        - 훈련 데이터가 에러, 이상치, 잡음으로 가득하다면, 머신러닝 시스템이 내재된 패턴을 찾기 어려워 잘 작동하지 않을 것입니다.\r\n",
        "        - 그래서 훈련 데이터 정제에 시간을 투자할 만한 가치는 충분합니다.\r\n",
        "    4. 관련 없는 특성 : \"garbage in, garbage out\"\r\n",
        "        - 성공적인 머신러닝 프로젝트의 핵심 요소는 훈련에 사용할 좋은 특성들을 찾는 것입니다.\r\n",
        "        - **특성 공학(feature engineering)**\r\n",
        "        - **특성 선택(feature selection)** : 가장 유용한 특성을 훈련에 사용\r\n",
        "        - **특성 추출(feature extraction)** : 특성을 결합하여 더 유용한 특성을 만듭니다.\r\n",
        "        (ex. 차원 축소 알고리즘을 사용할 수 있습니다)\r\n",
        "    5. 훈련 데이터 과대적합\r\n",
        "        - 과대 적합 : 모델이 훈련 데이터에 너무 잘 맞지만, 일반성이 떨어진다는 뜻.\r\n",
        "        - **규제(regularization)**:모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것.\r\n",
        "        - 학습하는 동안 적용할 규제의 양은 **하이퍼파라미터(hyperparameter)**가 결정합니다.\r\n",
        "        - 머신러닝 시스템을 구축할 때 하이퍼파라미터 튜닝은 매우 중요한 과정입니다.\r\n",
        "    6. 훈련데이터 과소적합\r\n",
        "        - 과소 적합 : 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 일어납니다. \r\n",
        "    7. 모델을 학습시켰다고 해서 새로운 샘플에 일반화 되길 그냥 바라기만 해서는 안됩니다. **모델을 평가**하고 필요하면, 상세하게 튜닝해야 합니다.\r\n",
        "5. 테스트와 검증 : 모델이 새루온 샘플에 얼마나 잘 일반화될지 아는 방법은 새로운 샘플에 실제로 적용해 보는 것입니다.\r\n",
        "    - 훈련 데이터를 **훈련 세트와 테스트 세트** 두 개로 나누는 것입니다.\r\n",
        "    - 새로운 샘플에 대한 오류 비율을 **일반화 오차(또는 외부 샘플 오차)**라고 합니다.\r\n",
        "    - 테스트 세트에서 모델을 평가함으로써 이 오차에 대한 **추정값(estimation)**을 얻습니다.\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73QwXI1M5IaF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}